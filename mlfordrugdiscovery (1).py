# -*- coding: utf-8 -*-
"""mlfordrugdiscovery.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NTGm5jmesHHZV8u_HJpJko8Qwx7n_NMF

# **Basic computational drug discovery project to build ML models using ChEMBL bioactivity data for SARS COV 2 protein.**

# **Part 1: Obtaining data from ChEMBL database**

ChEMBL is a manually curated database of bioactive molecules with drug-like properties. It brings together chemical, bioactivity and genomic data to aid the translation of genomic information into effective new drugs.
website: [ChEMBL](https://www.ebi.ac.uk/chembl/). We will install the ChEMBL web service package so that we can retrieve bioactivity data from the ChEMBL Database.

**Install and load libraries**
"""

! pip install chembl_webresource_client

import pandas as pd
from chembl_webresource_client.new_client import new_client

"""**Search for target protein**"""

target = new_client.target
target_query = target.search('coronavirus')
targets = pd.DataFrame.from_dict(target_query)
targets

"""Selected single protein for sars coronavirus2; that is present on index 7 in table above. we will retrieve only bioactivity data for this chembl id that are reported as pChEMBL values."""

selected_target = targets.target_chembl_id[7]
selected_target

activity = new_client.activity
res = activity.filter(target_chembl_id=selected_target).filter(standard_type="IC50")

df=pd.DataFrame.from_dict(res)

df

df.standard_type.unique()
## drop duplicates if required
# df_nr = df.drop_duplicates(['canonical_smiles'])
# df_nr

"""Now save this extracted data to file and push to google drive

"""

df.to_csv('bioactivity_data.csv', index=False)

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

! ls "/content/gdrive/My Drive/Colab Notebooks/"

! mkdir "/content/gdrive/My Drive/Colab Notebooks/data_ml"

! cp bioactivity_data.csv "/content/gdrive/My Drive/Colab Notebooks/data_ml"

! ls -l "/content/gdrive/My Drive/Colab Notebooks/data"

! ls

! head bioactivity_data.csv

"""**Handling missing value**

If any compounds has missing value for the standard_value and canonical_smiles column then drop it. Here there was no na value for smiles, so I have commented it.
"""

df2 = df[df.standard_value.notna()]
#  df2 = df2[df.canonical_smiles.notna()] ##if required
df2

"""**Data preprocessing**

**Labeling compounds as either being active, inactive or intermediate**
The bioactivity data is in the IC50 unit. Compounds having values of less than 1000 nM will be considered to be active while those greater than 10,000 nM will be considered to be inactive. As for those values in between 1,000 and 10,000 nM will be referred to as intermediate.
"""

bioactivity_class = []
for i in df2.standard_value:
  if float(i) >= 10000:
    bioactivity_class.append("inactive")
  elif float(i) <= 1000:
    bioactivity_class.append("active")
  else:
    bioactivity_class.append("intermediate")

"""Combine the 3 columns (molecule_chembl_id,canonical_smiles,standard_value) and bioactivity_class into a DataFrame"""

mol_cid = []
for i in df2.molecule_chembl_id:
  mol_cid.append(i)

canonical_smiles = []
for i in df2.canonical_smiles:
  canonical_smiles.append(i)

standard_value = []
for i in df2.standard_value:
  standard_value.append(i)

data_tuples = list(zip(mol_cid, canonical_smiles, bioactivity_class, standard_value))
df3 = pd.DataFrame( data_tuples,  columns=['molecule_chembl_id', 'canonical_smiles', 'bioactivity_class', 'standard_value'])

df3.head(4)

"""Alternate to create the four list and new data type. Below, df4 is same as df3"""

selection = ['molecule_chembl_id', 'canonical_smiles', 'standard_value']
df4 = df2[selection]
df4.head(4)

pd.concat([df4,pd.Series(bioactivity_class, name='class')], axis=1)

"""Saving resultant pre-processed data to drive."""

df3.to_csv('bioactivity_preprocessed_data.csv', index=False)

! ls -l

! cp bioactivity_preprocessed_data.csv "/content/gdrive/My Drive/Colab Notebooks/data_ml"

! ls "/content/gdrive/My Drive/Colab Notebooks/data"

"""# **PART 2:- exploratory data analysis**

performing Descriptor Calculation and Exploratory Data Analysis.
"""

! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh
! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh
! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local
! conda install -c rdkit rdkit -y
import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

"""**Load bioactivity data**"""

import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data_ml/bioactivity_preprocessed_data.csv')
df

"""**Lipinski descriptors**

Christopher Lipinski, a scientist at Pfizer, came up with a set of rule-of-thumb for evaluating the druglikeness of compounds. Such druglikeness is based on the Absorption, Distribution, Metabolism and Excretion (ADME) that is also known as the pharmacokinetic profile. Lipinski analyzed all orally active FDA-approved drugs in the formulation of what is to be known as the Rule-of-Five or Lipinski's Rule.

The Lipinski's Rule stated the following:

Molecular weight < 500 Dalton
Octanol-water partition coefficient (LogP) < 5
Hydrogen bond donors < 5
Hydrogen bond acceptors < 10
"""

import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors, Lipinski

# Inspired by: https://codeocean.com/explore/capsules?query=tag:data-curation

def lipinski(smiles, verbose=False):

    moldata= []
    for elem in smiles:
        # print(elem)
        mol=Chem.MolFromSmiles(elem) 
        moldata.append(mol)
       
    baseData= np.arange(1,1)
    i=0  
    for mol in moldata:        
       
        desc_MolWt = Descriptors.MolWt(mol)
        desc_MolLogP = Descriptors.MolLogP(mol)
        desc_NumHDonors = Lipinski.NumHDonors(mol)
        desc_NumHAcceptors = Lipinski.NumHAcceptors(mol)
           
        row = np.array([desc_MolWt,
                        desc_MolLogP,
                        desc_NumHDonors,
                        desc_NumHAcceptors])   
    
        if(i==0):
            baseData=row
        else:
            baseData=np.vstack([baseData, row])
        i=i+1      
    
    columnNames=["MW","LogP","NumHDonors","NumHAcceptors"]   
    descriptors = pd.DataFrame(data=baseData,columns=columnNames)
    
    return descriptors

"""Removing rows where canonical smiles is nan."""

df2 = df[df.canonical_smiles.notna()]

df2

df2_lipinski = lipinski(df2.canonical_smiles)

df2_lipinski

"""combine the two dataframes"""

df2.reset_index(drop=True, inplace=True)
df2_lipinski.reset_index(drop=True, inplace=True)
df_combined = pd.concat([df2,df2_lipinski], axis=1)

df_combined

df_combined.standard_value.describe()

df_combined.hist(column=["standard_value"])
df_combined.plot.scatter(x="molecule_chembl_id",y="standard_value")

def norm_value(input):
    norm = []

    for i in input['standard_value']:
        if i > 100000000:
          i = 100000000
        norm.append(i)

    input['standard_value_norm'] = norm
    x = input.drop('standard_value', 1)
        
    return x

"""IC50 is inhibitory concentration; how much conc. of drug is needed to inhibit a biological process by half.

We will first apply the norm_value() function so that the values in the standard_value column is normalized.
"""

df_norm = norm_value(df_combined)
df_norm

df_norm.standard_value_norm.describe()

"""### **Convert IC50 to pIC50**
To allow **IC50** data to be more uniformly distributed, we will convert **IC50** to the negative logarithmic scale which is essentially **-log10(IC50)**.

This custom function pIC50() will accept a DataFrame as input and will:
* Take the IC50 values from the ``standard_value`` column and converts it from nM to M by multiplying the value by 10$^{-9}$
* Take the molar value and apply -log10
* Delete the ``standard_value`` column and create a new ``pIC50`` column

Point to note: Values greater than 100,000,000 will be fixed at 100,000,000 otherwise the negative logarithmic value will become negative.
"""

# https://github.com/chaninlab/estrogen-receptor-alpha-qsar/blob/master/02_ER_alpha_RO5.ipynb

import numpy as np

def pIC50(input):
    pIC50 = []

    for i in input['standard_value_norm']:
        molar = i*(10**-9) # Converts nM to M
        pIC50.append(-np.log10(molar))

    input['pIC50'] = pIC50
    x = input.drop('standard_value_norm', 1)
        
    return x

df_final = pIC50(df_norm)
df_final
df_final.to_csv('bioactivity_data_3class_pIC50.csv', index=False)

! cp bioactivity_data_3class_pIC50.csv "/content/gdrive/My Drive/Colab Notebooks/data_ml"
! ls -l "/content/gdrive/My Drive/Colab Notebooks/data_ml"

df_final.hist(column="pIC50")## change in plot from standard value (IC50) to log(IC50)
df_final.plot.scatter(x="molecule_chembl_id",y="pIC50")

df_final.pIC50.describe()

"""### **Removing the 'intermediate' bioactivity class**
Here, we will be removing the ``intermediate`` class from our data set.
"""

df_2class = df_final[df_final.bioactivity_class != 'intermediate']
df_2class

"""## **Exploratory Data Analysis (Chemical Space Analysis) via Lipinski descriptors**"""

import seaborn as sns
sns.set(style='ticks')
import matplotlib.pyplot as plt

"""**Frequency plot of the 2 bioactivity classes**"""

plt.figure(figsize=(5.5, 5.5))

sns.countplot(x='bioactivity_class', data=df_2class, edgecolor='black')

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('Frequency', fontsize=14, fontweight='bold')

plt.savefig('plot_bioactivity_class.pdf')

plt.figure(figsize=(5.5, 5.5))

sns.scatterplot(x='MW', y='LogP', data=df_2class, hue='bioactivity_class', size='pIC50', edgecolor='black', alpha=0.7)

plt.xlabel('MW', fontsize=14, fontweight='bold')
plt.ylabel('LogP', fontsize=14, fontweight='bold')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)
plt.savefig('plot_MW_vs_LogP.pdf')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'pIC50', data = df_2class)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('pIC50 value', fontsize=14, fontweight='bold')

plt.savefig('plot_ic50.pdf')

"""**Statistical analysis | Mann-Whitney U Test**"""

def mannwhitney(descriptor, verbose=False):
  # https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/
  from numpy.random import seed
  from numpy.random import randn
  from scipy.stats import mannwhitneyu

# seed the random number generator
  seed(1)

# actives and inactives
  selection = [descriptor, 'bioactivity_class']
  # print(selection)
  df = df_2class[selection]
  # print(df)
  active = df[df.bioactivity_class == 'active']
  active = active[descriptor]

  selection = [descriptor, 'bioactivity_class']
  df = df_2class[selection]
  inactive = df[df.bioactivity_class == 'inactive']
  inactive = inactive[descriptor]

# compare samples
  stat, p = mannwhitneyu(active, inactive)
  #print('Statistics=%.3f, p=%.3f' % (stat, p))

# interpret
  alpha = 0.05
  if p > alpha:
    interpretation = 'Same distribution (fail to reject H0)'
  else:
    interpretation = 'Different distribution (reject H0)'
  
  results = pd.DataFrame({'Descriptor':descriptor,
                          'Statistics':stat,
                          'p':p,
                          'alpha':alpha,
                          'Interpretation':interpretation}, index=[0])
  filename = 'mannwhitneyu_' + descriptor + '.csv'
  results.to_csv(filename)

  return results

mannwhitney('pIC50')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'MW', data = df_2class)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('MW', fontsize=14, fontweight='bold')

plt.savefig('plot_MW.pdf')

mannwhitney('MW')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'LogP', data = df_2class)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('LogP', fontsize=14, fontweight='bold')

plt.savefig('plot_LogP.pdf')

mannwhitney('LogP')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'NumHDonors', data = df_2class)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('NumHDonors', fontsize=14, fontweight='bold')

plt.savefig('plot_NumHDonors.pdf')

mannwhitney('NumHDonors')

plt.figure(figsize=(5.5, 5.5))

sns.boxplot(x = 'bioactivity_class', y = 'NumHAcceptors', data = df_2class)

plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')
plt.ylabel('NumHAcceptors', fontsize=14, fontweight='bold')

plt.savefig('plot_NumHAcceptors.pdf')

mannwhitney('NumHAcceptors')

"""#### **Interpretation of Statistical Results**

##### **Box Plots**

###### **pIC50 values**

Taking a look at pIC50 values, the **actives** and **inactives** displayed ***statistically significant difference***, which is to be expected since threshold values (``IC50 < 1,000 nM = Actives while IC50 > 10,000 nM = Inactives``, corresponding to ``pIC50 > 6 = Actives and pIC50 < 5 = Inactives``) were used to define actives and inactives.

###### **Lipinski's descriptors**

All of the 4 Lipinski's descriptors exhibited ***statistically significant difference*** between the **actives** and **inactives**.
"""

! zip -r results.zip . -i *.csv *.pdf

! cp results.zip "/content/gdrive/My Drive/Colab Notebooks/data_ml"



"""# PART 3: **Descriptor Calculation and Dataset Preparation**

In Part 3, we will be calculating molecular descriptors that are essentially quantitative description of the compounds in the dataset. Finally, we will be preparing this into a dataset for subsequent model building in Part 4.

**Download PaDEL-Descriptor**
"""

! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip
! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh

! unzip padel.zip

"""**Load bioactivity data**

Download the curated ChEMBL bioactivity data that has been pre-processed from Parts 1 and 2 of this Bioinformatics Project series. Here we will be using the bioactivity_data_3class_pIC50.csv file that essentially contain the pIC50 values that we will be using for building a regression model.
"""

import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

df3 = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data_ml/bioactivity_data_3class_pIC50.csv')

selection = ['canonical_smiles','molecule_chembl_id']
df3_selection = df3[selection]
df3_selection.to_csv('molecule.smi', sep='\t', index=False, header=False)

! cat molecule.smi | head -5

! cat molecule.smi | wc -l

"""**Calculate fingerprint descriptors**

**Calculate PaDEL descriptors**
"""

! cat padel.sh

! bash padel.sh

! ls -l

"""**Preparing the X and Y Data Matrices**"""

df3_X = pd.read_csv('descriptors_output.csv')

df3_X

df3_X = df3_X.drop(columns=['Name'])
df3_X

df3_Y = df3['pIC50']
df3_Y

dataset3 = pd.concat([df3_X,df3_Y], axis=1)
dataset3

dataset3.to_csv('bioactivity_data_3class_pIC50_pubchem_fp.csv', index=False)

! cp bioactivity_data_3class_pIC50_pubchem_fp.csv "/content/gdrive/My Drive/Colab Notebooks/data_ml"



"""# Part 4:** Model building**

---

# ** Input features**
The ***Acetylcholinesterase*** data set contains 881 input features and 1 output variable (pIC50 values).

### **1. Input features**
"""

import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

df=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data_ml/bioactivity_data_3class_pIC50_pubchem_fp.csv')

X = df.drop('pIC50', axis=1)
X

"""### **2. Output features**"""

Y=df.pIC50
Y

print(X.shape,Y.shape)

"""### **3. Remove low variance features**"""

from sklearn.feature_selection import VarianceThreshold
selection = VarianceThreshold(threshold=(.8 * (1 - .8)))    
X = selection.fit_transform(X)

X.shape

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)
X_train.shape, Y_train.shape

"""### **4. Building a Regression Model using Random Forest**"""

import numpy as np
np.random.seed(100)
model = RandomForestRegressor(n_estimators=300)
model.fit(X_train, Y_train)
r2 = model.score(X_test, Y_test)
r2

Y_pred = model.predict(X_test)

"""### **5. Scatter Plot of Experimental vs Predicted pIC50 Values**"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.set(color_codes=True)
sns.set_style("white")

ax = sns.regplot(Y_test, Y_pred, scatter_kws={'alpha':0.4})
ax.set_xlabel('Experimental pIC50', fontsize='large', fontweight='bold')
ax.set_ylabel('Predicted pIC50', fontsize='large', fontweight='bold')
ax.set_xlim(3, 8.5)
ax.set_ylim(3, 8.5)
ax.figure.set_size_inches(5, 5)
plt.show



"""# Part 5: **compare regression models**

comparing several ML algorithms for build regression models of sars cov2 inhibitors.
"""

! pip install lazypredict

import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
import lazypredict
from lazypredict.Supervised import LazyRegressor

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

df=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data_ml/bioactivity_data_3class_pIC50_pubchem_fp.csv')

X = df.drop('pIC50', axis=1)
Y = df.pIC50

print(X.shape,Y.shape)

from sklearn.feature_selection import VarianceThreshold
selection = VarianceThreshold(threshold=(.8 * (1 - .8)))    
X = selection.fit_transform(X)
X.shape

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)#, random_state=42)

"""**Compare ML algorithms**"""

clf = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None)
train,test=clf.fit(X_train,X_test,Y_train,Y_test)
# models_train,predictions_train = clf.fit(X_train, X_train, Y_train, Y_train)
# models_test,predictions_test = clf.fit(X_train, X_test, Y_train, Y_test)

train

test

"""**Data visualization of model performance**"""

# Bar plot of R-squared values
import matplotlib.pyplot as plt
import seaborn as sns

#train["R-Squared"] = [0 if i < 0 else i for i in train.iloc[:,0] ]

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=train.index, x="R-Squared", data=train)
ax.set(xlim=(0, 1))

# Bar plot of RMSE values
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=train.index, x="RMSE", data=train)
ax.set(xlim=(0, 10))

# Bar plot of calculation time
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=train.index, x="Time Taken", data=train)
ax.set(xlim=(0, 10))

